{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('ALS').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------+\n",
      "|movie_id|rating|user_id|\n",
      "+--------+------+-------+\n",
      "|      31|   2.5|      1|\n",
      "|    1029|   3.0|      1|\n",
      "|    1061|   3.0|      1|\n",
      "|    1129|   2.0|      1|\n",
      "|    1172|   4.0|      1|\n",
      "|    1263|   2.0|      1|\n",
      "|    1287|   2.0|      1|\n",
      "|    1293|   2.0|      1|\n",
      "|    1339|   3.5|      1|\n",
      "|    1343|   2.0|      1|\n",
      "|    1371|   2.5|      1|\n",
      "|    1405|   1.0|      1|\n",
      "|    1953|   4.0|      1|\n",
      "|    2105|   4.0|      1|\n",
      "|    2150|   3.0|      1|\n",
      "|    2193|   2.0|      1|\n",
      "|    2294|   2.0|      1|\n",
      "|    2455|   2.5|      1|\n",
      "|    2968|   1.0|      1|\n",
      "|    3671|   3.0|      1|\n",
      "+--------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "ratings_rdd = spark.sparkContext \\\n",
    "                   .textFile('../data/ratings.csv') \\\n",
    "                   .map(lambda line: line.split(',')) \\\n",
    "                   .map(lambda values: Row(user_id=int(values[0]), \n",
    "                                           movie_id=int(values[1]), \n",
    "                                           rating=float(values[2])))\n",
    "\n",
    "ratings_df = spark.createDataFrame(ratings_rdd)\n",
    "ratings_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "(training, test) = ratings_df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# TODO: train ALS model with rank=8, maxIter=10 and nonnegative=True\n",
    "als = ALS(rank=8, maxIter=10, nonnegative=True, userCol='user_id', itemCol='movie_id', ratingCol='rating')\n",
    "\n",
    "als_model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = als_model.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------+----------+\n",
      "|movie_id|rating|user_id|prediction|\n",
      "+--------+------+-------+----------+\n",
      "|     148|   4.0|    575|  3.885124|\n",
      "|     463|   4.0|    232| 3.8574328|\n",
      "|     463|   2.0|    452| 2.3836129|\n",
      "|     463|   3.0|    380| 3.0937757|\n",
      "|     463|   4.0|    242| 3.7774878|\n",
      "|     463|   4.0|     30| 3.5408144|\n",
      "|     471|   3.0|     85| 3.0263326|\n",
      "|     471|   5.0|    126| 3.9464946|\n",
      "|     471|   3.0|    350| 3.5577257|\n",
      "|     471|   3.0|    602|  3.979167|\n",
      "|     471|   5.0|    285|  4.015639|\n",
      "|     471|   5.0|    274| 3.8304222|\n",
      "|     471|   3.0|    440| 3.0133495|\n",
      "|     471|   4.0|     86| 4.2924595|\n",
      "|     471|   3.0|    306| 3.2781227|\n",
      "|     471|   3.0|     19| 4.0349836|\n",
      "|     471|   4.0|     92|   3.93749|\n",
      "|     471|   4.5|    299|  4.564701|\n",
      "|     471|   4.0|    309| 4.2943807|\n",
      "|     471|   4.0|    607| 3.4679222|\n",
      "+--------+------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.917013558202422\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import isnan\n",
    "\n",
    "# TODO: make predictions for test data\n",
    "\n",
    "prediction = als_model.transform(test)\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName='rmse',\n",
    "                                labelCol='rating',\n",
    "                                predictionCol='prediction')\n",
    "\n",
    "print(evaluator.evaluate(prediction.filter(~isnan('prediction'))))\n",
    "\n",
    "# TODO: evaluate predictions with RegressionEvaluator\n",
    "# NOTE: remove records with isnan('prediction') == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------+----------+\n",
      "|movie_id|rating|user_id|prediction|\n",
      "+--------+------+-------+----------+\n",
      "|    4101|   4.5|    580|       NaN|\n",
      "|   32460|   5.0|    298|       NaN|\n",
      "|  141422|   2.5|    624|       NaN|\n",
      "|   51927|   3.0|    584|       NaN|\n",
      "|    2776|   3.0|    436|       NaN|\n",
      "|    6559|   4.0|     73|       NaN|\n",
      "|   34435|   4.5|    572|       NaN|\n",
      "|   61250|   5.0|    599|       NaN|\n",
      "|     251|   3.0|    516|       NaN|\n",
      "|    2923|   4.0|    597|       NaN|\n",
      "|    4000|   3.0|    444|       NaN|\n",
      "|   36533|   2.5|    384|       NaN|\n",
      "|      53|   5.0|    344|       NaN|\n",
      "|    3790|   4.0|    407|       NaN|\n",
      "|    4092|   2.5|     77|       NaN|\n",
      "|  134158|   1.5|    624|       NaN|\n",
      "|   26350|   4.5|    547|       NaN|\n",
      "|    1133|   3.0|    318|       NaN|\n",
      "|    2625|   4.0|    346|       NaN|\n",
      "|    4725|   4.5|     17|       NaN|\n",
      "+--------+------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.filter(isnan('prediction')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
